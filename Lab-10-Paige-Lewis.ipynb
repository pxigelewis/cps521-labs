{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2fece99-2f2e-4d14-b8f0-78a9bdbf119f",
   "metadata": {},
   "source": [
    "####\n",
    "Instructions for lab 10:\n",
    "1. using NLTK word_tokenize function, tokenize the given dataset reviews\n",
    "2. Using NLTK PorterStemmer, perform the stemming for the tokens of the reviews\n",
    "3. Using NLTK WordNetLemmatizer, perform the lemmatization for the stemmed tokens\n",
    "4. Build the Random Forest technique using sklearn library\n",
    "5. Evaluate the model by finding its accuracy, precision, and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3037fef8-cd57-4225-97d3-f886b4309560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/paigelewis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/paigelewis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/paigelewis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download(['stopwords', 'punkt', 'wordnet'])\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b7110dd6-d43c-4f9a-9012-f2f5cea232fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This the second set of strap locks that I've o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First of all I want to say I love a tube amp d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i only bought with the idea that a \"FULL\" vers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're like me, you probably bought this to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Didn't know what to expect for under $10, but ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Score\n",
       "0  This the second set of strap locks that I've o...      1\n",
       "1  First of all I want to say I love a tube amp d...      1\n",
       "2  i only bought with the idea that a \"FULL\" vers...      0\n",
       "3  If you're like me, you probably bought this to...      1\n",
       "4  Didn't know what to expect for under $10, but ...      1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('musical1.tsv', sep = '\\t')\n",
    "df.head()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8b5a1b2d-b6a6-4b5b-86c4-b62eae69aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract words from review column in data\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "corpus = []\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "for word in df['Review']:\n",
    "    words = word.lower()\n",
    "    words = \"\".join([ch for ch in word if ch.isalnum() or ch==' '])   #gets rid of punctuation\n",
    "    words = words.split() #converts into a list\n",
    "    tokenizer.fit_on_texts(words)\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "    words = ' '.join(words)\n",
    "    corpus.append(words)\n",
    "#print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "643a540e-bace-4f72-bbad-e1277f785784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "vectors = tokenizer.texts_to_matrix(words, mode = 'count')\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0aecbe99-4421-41fd-8e2b-d9afd7fb5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countVect = CountVectorizer(max_features = 5000)\n",
    "\n",
    "x = countVect.fit_transform(corpus).toarray()\n",
    "y = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2009cc22-98b5-4927-be1e-a89504cd200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6dfb4bd0-f20e-41b9-8d0e-18c7f93a3b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier\n",
    "\n",
    "#fitting the classifier to the training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 400, criterion = 'entropy', random_state = 1)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "#predicting test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm2 = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9dbbc913-3e6f-430d-9d27-60cea60d0666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[91 16]\n",
      " [32 61]]\n",
      "\n",
      "Test metrics:\n",
      "Accuracy: 76.0%\n",
      "Precision: 85.04672897196261%\n",
      "Recall: 73.98373983739837%\n",
      "F1-score: 79.1304347826087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "acc = accuracy_score(y_test, np.round(y_pred))*100\n",
    "cm = confusion_matrix(y_test, np.round(y_pred), labels=[1,0])\n",
    "tp = cm[0][0]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "tn = cm[1][1]\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print()\n",
    "print(\"Test metrics:\")\n",
    "precision = tp / (tp+fp)*100\n",
    "recall = tp/(tp+fn)*100\n",
    "print('Accuracy: {}%'.format(acc))\n",
    "print('Precision: {}%'.format(precision))\n",
    "print('Recall: {}%'.format(recall))\n",
    "print('F1-score: {}'.format(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f6d21-b403-4cf3-9e3b-ab941bafccde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
